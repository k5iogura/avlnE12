{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# プロダクト開発演習  \n",
    "## テーマ：JPEG圧縮画像の超解像モデル開発  \n",
    "### 摘要  \n",
    "**画像の保存領域削減のため縮小かつJPEG圧縮された画像を補完して美しく参照するため、JPEG圧縮画像の超解像モデルを開発する。JPEG圧縮画像の超解像モデルを実装し超解像処理結果の確認と考察を行う。基本とするニューラルネットワークモデルはSRCNNとし、Pytorchフレームワーク上に参照論文記載の構成を実装した。まず初めに、BICUBIC拡大縮小画像を学習対象として、SRCNNの基本性能を確認した。次に、BICUBIC拡大縮小に加えて、OoenCVによるJPEG圧縮処理した画像を学習対象として、複数のモデルを提案し、その性能を評価した。データセットとして、[General100](http://mmlab.ie.cuhk.edu.hk/projects/FSRCNN.html)データセットを用い学習並びにホールドアウト法によるPSNR(dB)にて評価を行った。最後に、テスト結果(testview.ipynb)検討から提案モデルの優劣を考察した。**  \n",
    "\n",
    "**学習処理(train.ipynb)概要（本jupyter-notebook）**  \n",
    "  1. 環境定義  \n",
    "  2. データローディングとデータ拡張、画像劣化処理\n",
    "  3. モデル定義とインスタンス  \n",
    "  4. 学習ループ  \n",
    "\n",
    "**学習結果表示処理(viewres.ipynb)**  \n",
    "学習過程のPSNRとLossグラフ化  \n",
    "\n",
    "**テストデータ評価(testview.ipynb)**  \n",
    "テスト用画像を用いた各モデルの評価とPSNRまとめ\n",
    "\n",
    "### 参照論文モデル(train.ipynb)  \n",
    "**SRCNN**    \n",
    "参照論文:\"Chao Dong, Chen Change Loy, Kaiming He, Xiaoou Tang. Learning a Deep Convolutional Network for Image Super-Resolution, in Proceedings of European Conference on Computer Vision (ECCV), 2014\"  \n",
    "\n",
    "### 学習データ及びデータ拡張  \n",
    "[General100 Dataset](http://mmlab.ie.cuhk.edu.hk/projects/FSRCNN.html)を学習データとして用いる  \n",
    "100画像を学習用途80、バリデーション用途、テスト用途に各10画像に分け学習を行うが、データセットのダウンロード、展開、dataディレクトリへの分割については[付録参照](#学習データ)  \n",
    "**データ拡張：PILのFlip, Mirror, Rotateを実装**  \n",
    "**画像劣化手法：PILのBICUBLIC拡大縮小並びにOpenCVによるJPEG圧縮処理を実装**  \n",
    "\n",
    "### 提案モデル(train.ipynb)  \n",
    "**特徴抽出層のカーネルサイズ9x9に11x11の特徴抽出層を追加：SRCNN11**  \n",
    "演算量は同等のまま特徴抽出方法を変更  \n",
    "広範囲の特徴を加味した推論を可能とする  \n",
    "**5層モデル：SYM**  \n",
    "SRCNNに残差機構を追加し、低層の情報を上位層へ直接伝えると共に、勾配消失を回避  \n",
    "\n",
    "### 学習結果(viewres.ipynb)\n",
    "**PSNRの推移グラフ：学習結果(dB推移)をnpyで保存し、別ipynb(viewres.ipynb)で表示**  \n",
    "自身のGPU環境ではjupyter-notebook未サポートのため \n",
    "\n",
    "### 考察並びに改善案(testview.ipynb)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**環境定義**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "if __name__=='__main__':\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description='SRCNN Training')\n",
    "    parser.add_argument('--cuda' , action='store_true', default=False)\n",
    "    parser.add_argument('--naive', action='store_true', default=False)\n",
    "    parser.add_argument('--c11'  , action='store_true', default=False)\n",
    "    parser.add_argument('--sym'  , action='store_true', default=False)\n",
    "    parser.add_argument('--comp' , action='store_true', default=False)\n",
    "    parser.add_argument('--q'    , type=int, default=10,help='Compress Quality Factor')\n",
    "    parser.add_argument('--epoch', type=int, default=50*1000)\n",
    "    parser.add_argument('--snap' , type=int, default=500)\n",
    "    parser.add_argument('--con'  , action='store_true', default=False)\n",
    "    if Path(sys.argv[0]).stem == 'ipykernel_launcher':\n",
    "        # On Jupyter\n",
    "        args = []\n",
    "#       args.append(\"--comp\")\n",
    "#       args.append(\"--naive\")\n",
    "#       args.append(\"--c11\")\n",
    "        args.append(\"--sym\")\n",
    "        args.append(\"--con\")\n",
    "#       args.append(\"--q\")\n",
    "#       args.append(\"--epoch\")\n",
    "#       args.extend([\"--snap\",\"5\"])\n",
    "#       args.append(\"--q\",\"8\")\n",
    "        opt = parser.parse_args(args=args)\n",
    "    else:\n",
    "        # On Console python3\n",
    "        opt = parser.parse_args()\n",
    "\n",
    "    result_fileout=not opt.con  #To fileout\n",
    "    result_dir=Path('result')\n",
    "    if opt.comp:\n",
    "        result_dir = Path(str(result_dir)+'-comp'+str(opt.q))\n",
    "    result_dir/='SRCNN'    \n",
    "    if opt.naive:\n",
    "        result_dir = Path(str(result_dir)+'-naive')\n",
    "    if opt.c11:\n",
    "        result_dir = Path(str(result_dir)+'-c11')\n",
    "    if opt.sym:\n",
    "        result_dir = Path(str(result_dir)+'-sym')\n",
    "\n",
    "    sample_dir = result_dir / 'sample'\n",
    "    weight_dir = result_dir / 'weights'\n",
    "    os.makedirs(str(sample_dir), exist_ok=True)\n",
    "    os.makedirs(str(weight_dir), exist_ok=True)\n",
    "    os.makedirs(str(result_dir),exist_ok=True)\n",
    "    resultdB = result_dir / 'dBhistory.npy'\n",
    "    backup_stdout = backup_stderr = None\n",
    "    if result_fileout:\n",
    "        backup_stdout = sys.stdout\n",
    "        backup_stderr = sys.stderr\n",
    "        sys.stdout = open(str(result_dir)+'/log.stdout','w')\n",
    "        sys.stderr = open(str(result_dir)+'/log.stderr','w')\n",
    "    print(\"Result on {}, File : {}\".format(result_dir, resultdB))\n",
    "    print(\" CUDA  : {}\".format(opt.cuda))\n",
    "    print(\" AUG   : {}\".format(not opt.naive))\n",
    "    print(\" C11   : {}\".format(opt.c11))\n",
    "    print(\" SYM   : {}\".format(opt.sym))\n",
    "    print(\" COMP  : {}\".format(opt.comp))\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import numpy as np\n",
    "from math import log10\n",
    "\n",
    "# from model import SRCNN\n",
    "from torch.nn.functional import relu\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor, RandomCrop\n",
    "from PIL import Image, ImageOps\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import random\n",
    "from pdb import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SRCNNモデル定義(SRCNN)  \n",
    "論文に従いモデルを定義   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=9, padding=4)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=1, padding=0)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=3, kernel_size=5, padding=2)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d)):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.001)\n",
    "                nn.init.constant_(m.bias, val=0)\n",
    "\n",
    "            self.params = [\n",
    "                        {'params': self.conv1.parameters()},\n",
    "                        {'params': self.conv2.parameters()},\n",
    "                        {'params': self.conv3.parameters(),\n",
    "                        'lr': 1e-5}]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = relu(x)\n",
    "        x = self.conv3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11x11カーネルを持つSRCNN(SRCNN-c11)  \n",
    "原論文では、カーネルサイズ９x９の特徴抽出層が第１層に当たる  \n",
    "これにカーネルサイズ１１x１１の層を追加し広範囲の特徴抽出を行う  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNN11(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRCNN11, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=9, padding=4)\n",
    "        self.conv11= nn.Conv2d(in_channels=3, out_channels=32, kernel_size=11, padding=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=1, padding=0)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=3, kernel_size=5, padding=2)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d)):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.001)\n",
    "                nn.init.constant_(m.bias, val=0)\n",
    "\n",
    "        self.params = [\n",
    "                        {'params': self.conv1.parameters()},\n",
    "                        {'params': self.conv11.parameters()},\n",
    "                        {'params': self.conv2.parameters()},\n",
    "                        {'params': self.conv3.parameters(),\n",
    "                        'lr': 1e-5}]\n",
    "    def forward(self, x):\n",
    "        x9 = self.conv1(x)\n",
    "        x9 = relu(x9)\n",
    "        x11 = self.conv11(x)\n",
    "        x11 = relu(x11)\n",
    "        x = torch.cat((x9, x11),dim=1)\n",
    "        x = self.conv2(x)\n",
    "        x = relu(x)\n",
    "        x = self.conv3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5層モデル(SYM)  \n",
    "SRCNNに残差機構を追加し、低層の情報を上位層へ直接伝えると共に、勾配消失を回避:SYMモデル  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SYM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SYM, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=9, padding=4)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=1, padding=0)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=3, kernel_size=5, padding=2)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d)):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.001)\n",
    "                nn.init.constant_(m.bias, val=0)\n",
    "\n",
    "            self.params = [\n",
    "                        {'params': self.conv1.parameters()},\n",
    "                        {'params': self.conv2.parameters()},\n",
    "                        {'params': self.conv3.parameters()},\n",
    "                        {'params': self.conv4.parameters(),\n",
    "                        'lr': 1e-5}]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) # 64\n",
    "        x1 = relu(x)\n",
    "        x = self.conv2(x1) #128\n",
    "        x = relu(x)\n",
    "        x = self.conv3(x) # 64\n",
    "        x = relu(x) + x1\n",
    "        x = self.conv4(x) # 3\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用モデルのインスタンス  \n",
    "モデルインスタンス  \n",
    "オプティマイザ定義  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "    if opt.c11:\n",
    "        print('load model: SRCNN11')\n",
    "        model = SRCNN11()\n",
    "    elif opt.sym:\n",
    "        print('load model: SYM')\n",
    "        model = SYM()\n",
    "    else:\n",
    "        print('load model: SRCNN')\n",
    "        model = SRCNN()\n",
    "\n",
    "    criterion = MSELoss()\n",
    "    if opt.cuda:\n",
    "        model = model.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "\n",
    "    optimizer = optim.Adam( model.parameters(), lr=1e-4 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データローダ定義  \n",
    "学習用画像のミニバッチをロード  \n",
    "評価用画像を1枚づつロード  \n",
    "イテレータを戻す  \n",
    "\n",
    "### 画像劣化モデル  \n",
    "**BICUBLIC拡大縮小処理  \n",
    "JPEG圧縮**  \n",
    "\n",
    "### データ拡張  \n",
    "flip  \n",
    "mirror  \n",
    "rotate  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(img, Quality=10):\n",
    "    img = np.array(img)\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), Quality]\n",
    "    result, img = cv2.imencode(\".jpg\", img, encode_param) # JPEG Encode\n",
    "    out_img = cv2.imdecode(img, cv2.IMREAD_UNCHANGED)\n",
    "    out_img  = Image.fromarray(np.uint8(out_img))\n",
    "    return out_img\n",
    "\n",
    "class DatasetLoader4Train(data.Dataset):\n",
    "    def __init__(self, image_dir, patch_size, scale_factor, data_augmentation=True, comp=False, quality=10):\n",
    "        super(DatasetLoader4Train, self).__init__()\n",
    "        self.filenames = [str(filename) for filename in Path(image_dir).glob('*') if filename.suffix in ['.bmp', '.jpg', '.png']]\n",
    "        self.patch_size = patch_size\n",
    "        self.scale_factor = scale_factor\n",
    "        self.data_augmentation = data_augmentation\n",
    "        self.crop = RandomCrop(self.patch_size)\n",
    "        self.comp = comp\n",
    "        self.quality = quality\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        target_img = Image.open(self.filenames[index]).convert('RGB')\n",
    "        target_img = self.crop(target_img)\n",
    "\n",
    "        # Data Augmentation\n",
    "        if self.data_augmentation:\n",
    "            if random.random() < 0.5:\n",
    "                target_img = ImageOps.flip(target_img)\n",
    "            if random.random() < 0.5:\n",
    "                target_img = ImageOps.mirror(target_img)\n",
    "            if random.random() < 0.5:\n",
    "                target_img = target_img.rotate(180)\n",
    "\n",
    "        # BICUBIC\n",
    "        input_img = target_img.resize((self.patch_size // self.scale_factor,) * 2, Image.BICUBIC)\n",
    "        input_img = input_img.resize((self.patch_size,) * 2, Image.BICUBIC)\n",
    "\n",
    "        # COMPRESS\n",
    "        if self.comp:input_img = compress(input_img, self.quality)\n",
    "\n",
    "        return ToTensor()(input_img), ToTensor()(target_img)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "class DatasetLoader4Eval(data.Dataset):\n",
    "    def __init__(self, image_dir, scale_factor, comp=False, quality=10):\n",
    "        super(DatasetLoader4Eval, self).__init__()\n",
    "        self.filenames = [str(filename) for filename in Path(image_dir).glob('*') if filename.suffix in ['.bmp', '.jpg', '.png']]\n",
    "        self.scale_factor = scale_factor\n",
    "        self.comp = comp\n",
    "        self.quality = quality\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        target_img = Image.open(self.filenames[index]).convert('RGB')\n",
    "\n",
    "        # BICUBIC\n",
    "        input_img = target_img.resize((target_img.size[0] // self.scale_factor, target_img.size[1] // self.scale_factor), Image.BICUBIC)\n",
    "        input_img = input_img.resize(target_img.size, Image.BICUBIC)\n",
    "\n",
    "        # COMPRESS\n",
    "        if self.comp: input_img = compress(input_img,self.quality)\n",
    "            \n",
    "        return ToTensor()(input_img), ToTensor()(target_img), Path(self.filenames[index]).stem\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop with MiniBatch  \n",
    "epoch and snapshot size can be specified command args  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__=='__main__':\n",
    "\n",
    "    train_set = DatasetLoader4Train(image_dir='./data/General-100/train', patch_size=96, scale_factor=4, data_augmentation=not opt.naive, comp=opt.comp)\n",
    "    train_loader = DataLoader(dataset=train_set, batch_size=10, shuffle=True)\n",
    "\n",
    "    val_set = DatasetLoader4Eval(image_dir='./data/General-100/val', scale_factor=4, comp=opt.comp)\n",
    "    val_loader = DataLoader(dataset=val_set, batch_size=1, shuffle=False)\n",
    "\n",
    "    try:\n",
    "        epochs = opt.epoch\n",
    "        snaps  = opt.snap\n",
    "    except:\n",
    "        epochs = 5*10000\n",
    "        snaps  = 5*  100\n",
    "    trainProgress = []\n",
    "#   progressLoss = []\n",
    "    from pdb import set_trace\n",
    "    for epoch in range(epochs):\n",
    "        model.train() # Training Phase\n",
    "        epoch_loss, epoch_psnr = 0, 0\n",
    "        for batch in train_loader:\n",
    "            inputs, targets = Variable(batch[0]), Variable(batch[1])\n",
    "            if opt.cuda:\n",
    "                inputs = inputs.cuda()\n",
    "                targets = targets.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            prediction = model(inputs)\n",
    "            loss = criterion(prediction, targets)\n",
    "            epoch_loss += float(loss.data)\n",
    "            epoch_psnr += 10 * log10(1 / loss.data)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        avrg_train_loss = epoch_loss / len(train_loader) # TrainData Pred vs GTruth\n",
    "        avrg_train_psnr = epoch_psnr / len(train_loader)\n",
    "        print('[Epoch {}] Loss: {:.4f}, PSNR: {:.4f} dB'.format(epoch + 1, avrg_train_loss, avrg_train_psnr))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        if (epoch + 1) % snaps != 0:\n",
    "            continue\n",
    "\n",
    "        model.eval()  # Validation Phase\n",
    "        val_loss, val_psnr = 0, 0\n",
    "        val_loss0,val_psnr0= 0, 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                inputs, targets = batch[0], batch[1]\n",
    "                if opt.cuda:\n",
    "                    inputs = inputs.cuda()\n",
    "                    targets = targets.cuda()\n",
    "\n",
    "                prediction = model(inputs)\n",
    "                loss = criterion(prediction, targets)\n",
    "                val_loss += float(loss.data)\n",
    "                val_psnr += 10 * log10(1 / loss.data)\n",
    "            \n",
    "                loss0= criterion(inputs, targets)\n",
    "                val_loss0+= float(loss0.data)\n",
    "                val_psnr0+= 10 * log10(1 / loss0.data)\n",
    "\n",
    "                pred_file   = sample_dir / '{}_epoch{:05}.png'.format(batch[2][0], epoch + 1)\n",
    "                target_file = sample_dir / '{}_epoch{:05}.png'.format(batch[2][0], 00000)\n",
    "                save_image(prediction, pred_file, nrow=1)\n",
    "                if not target_file.exists(): save_image(targets, target_file, nrow=1)\n",
    "\n",
    "        avrg_val_loss0= val_loss0/ len(val_loader) # ValData Input vs GTruth\n",
    "        avrg_val_psnr0= val_psnr0/ len(val_loader)\n",
    "        avrg_val_loss = val_loss / len(val_loader) # ValData Prediction vs GTruth\n",
    "        avrg_val_psnr = val_psnr / len(val_loader)\n",
    "        trainProgress.append([ avrg_train_loss, avrg_train_psnr, avrg_val_loss, avrg_val_psnr ]) # TrainLoss, TrainPSNR, ValLoss, ValPSNR\n",
    "\n",
    "        print(\"===> Avrg Loss: {:.4f} PSNR: {:.4f} dB [ VAL {:.4f} / {:.4f} dB ]\".format(avrg_val_loss, avrg_val_psnr, avrg_val_loss0, avrg_val_psnr0))\n",
    "        np.save(str(resultdB),trainProgress)\n",
    "    \n",
    "        torch.save(model.state_dict(), str(result_dir / 'latest_weight.pth')) # Save Latest Weight\n",
    "        torch.save(model.state_dict(), str(weight_dir / 'weight_epoch{:05}.pth'.format(epoch + 1)))\n",
    "\n",
    "    # retrieve stdio\n",
    "    if result_fileout:\n",
    "        sys.stdout = backup_stdout if backup_stdout else None\n",
    "        sys.stderr = backup_stderr if backup_stderr else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習結果(viewres.ipynb)\n",
    "**viewres.ipynbにて学習処理の結果表示並びに考察**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"学習データ\"></a>  \n",
    "**付録**  \n",
    "学習データは、提供サイトよりダウンロード、圧縮展開後、以下の３つのディレクトリへ分けて置く  \n",
    "data/General-100/train data/General-100/val data/General-100/test  \n",
    "学習データ80画像、バリデーション10画像、テスト10画像をランダムに選択  \n",
    "\n",
    "**提出物**  \n",
    "train.ipynb  \n",
    "viewres.ipynb  \n",
    "testview.ipynb  \n",
    "result/SRCNN/latest_weight.pth  \n",
    "result/SRCNN-naive/latest_weight.pth  \n",
    "result-comp10/SRCNN/latest_weight.pth  \n",
    "result-comp10/SRCNN-c11/latest_weight.pth  \n",
    "result-comp10/SRCNN-sym/latest_weight.pth  \n",
    "result/SRCNN/dBhistory.npy  \n",
    "result/SRCNN-naive/dBhistory.npy  \n",
    "result-comp10/SRCNN/dBhistory.npy  \n",
    "result-comp10/SRCNN-c11/dBhistory.npy  \n",
    "result-comp10/SRCNN-sym/dBhistory.npy  \n",
    "data/General-100/test/im_\\*.bmp    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
