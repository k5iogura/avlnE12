{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SRCNN Super Resolution CNN with pytorch  \n",
    "## Training ipython for General100 Ddataset.  \n",
    "Exercise for Product making. \n",
    "  1. Initialize to run SRCNN Model  \n",
    "  2. Load Data General 100   \n",
    "  3. Load Model  \n",
    "  4. Loop step of training with outputs  \n",
    "\n",
    "Ref.  \n",
    "Chao Dong, Chen Change Loy, Kaiming He, Xiaoou Tang. Learning a Deep Convolutional Network for Image Super-Resolution, in Proceedings of European Conference on Computer Vision (ECCV), 2014 \n",
    "\n",
    "stdout, stderr, weight and samples are saved into result directory.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='predictionCNN Example')\n",
    "parser.add_argument('--cuda' , action='store_true', default=False)\n",
    "parser.add_argument('--naive', action='store_true', default=False)\n",
    "parser.add_argument('--c11'  , action='store_true', default=False)\n",
    "parser.add_argument('--con'  , action='store_true', default=False)\n",
    "parser.add_argument('--epoch', type=int, default=50*1000)\n",
    "parser.add_argument('--snap' , type=int, default=500)\n",
    "if Path(sys.argv[0]).stem == 'ipykernel_launcher':\n",
    "    # On IPython\n",
    "    opt = parser.parse_args(args=[])\n",
    "    # opt = parser.parse_args(args=[\"--cuda\"])\n",
    "    # opt = parser.parse_args(args=[\"--naive\"])\n",
    "    # opt = parser.parse_args(args=[\"--c11\"])\n",
    "    # opt = parser.parse_args(args=[\"--snap\",\"5\"])\n",
    "else:\n",
    "    # On Console\n",
    "    opt = parser.parse_args()\n",
    "\n",
    "result_fileout=not opt.con  #To fileout\n",
    "result_dir=Path('result/SRCNN')    \n",
    "if opt.naive:\n",
    "    result_dir = Path(str(result_dir)+'-naive')\n",
    "if opt.c11:\n",
    "    result_dir = Path(str(result_dir)+'-c11')\n",
    "\n",
    "sample_dir = result_dir / 'sample'\n",
    "weight_dir = result_dir / 'weights'\n",
    "os.makedirs(str(sample_dir), exist_ok=True)\n",
    "os.makedirs(str(weight_dir), exist_ok=True)\n",
    "os.makedirs(str(result_dir),exist_ok=True)\n",
    "resultdB = result_dir / 'dBhistory.npy'\n",
    "backup_stdout = backup_stderr = None\n",
    "if result_fileout:\n",
    "    backup_stdout = sys.stdout\n",
    "    backup_stderr = sys.stderr\n",
    "    sys.stdout = open(str(result_dir)+'/log.stdout','w')\n",
    "    sys.stderr = open(str(result_dir)+'/log.stderr','w')\n",
    "print(\"Result on {} file : {}\".format(result_dir, resultdB))\n",
    "print(\" CUDA  : {}\".format(opt.cuda))\n",
    "print(\" AUG   : {}\".format(not opt.naive))\n",
    "print(\" C11   : {}\".format(opt.c11))\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import numpy as np\n",
    "from math import log10\n",
    "\n",
    "# from model import SRCNN\n",
    "from torch.nn.functional import relu\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor, RandomCrop\n",
    "from PIL import Image, ImageOps\n",
    "from pathlib import Path\n",
    "import random\n",
    "from pdb import set_trace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データローダ定義  \n",
    "学習用画像のミニバッチをロード  \n",
    "評価用画像を1枚づつロード  \n",
    "イテレータを戻す  \n",
    "\n",
    "### データ拡張  \n",
    "基本的なデータ拡張を行うことにより、1dB程度の精度改善  \n",
    "flip  \n",
    "mirror  \n",
    "rotate  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetLoader4Train(data.Dataset):\n",
    "    def __init__(self, image_dir, patch_size, scale_factor, data_augmentation=True):\n",
    "        super(DatasetLoader4Train, self).__init__()\n",
    "        self.filenames = [str(filename) for filename in Path(image_dir).glob('*') if filename.suffix in ['.bmp', '.jpg', '.png']]\n",
    "        self.patch_size = patch_size\n",
    "        self.scale_factor = scale_factor\n",
    "        self.data_augmentation = data_augmentation\n",
    "        self.crop = RandomCrop(self.patch_size)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        target_img = Image.open(self.filenames[index]).convert('RGB')\n",
    "        target_img = self.crop(target_img)\n",
    "\n",
    "        if self.data_augmentation:     # Data Augmentation\n",
    "            if random.random() < 0.5:\n",
    "                target_img = ImageOps.flip(target_img)\n",
    "            if random.random() < 0.5:\n",
    "                target_img = ImageOps.mirror(target_img)\n",
    "            if random.random() < 0.5:\n",
    "                target_img = target_img.rotate(180)\n",
    "        input_img = target_img.resize((self.patch_size // self.scale_factor,) * 2, Image.BICUBIC)\n",
    "        input_img = input_img.resize((self.patch_size,) * 2, Image.BICUBIC)\n",
    "\n",
    "        return ToTensor()(input_img), ToTensor()(target_img)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "class DatasetLoader4Eval(data.Dataset):\n",
    "    def __init__(self, image_dir, scale_factor):\n",
    "        super(DatasetLoader4Eval, self).__init__()\n",
    "        self.filenames = [str(filename) for filename in Path(image_dir).glob('*') if filename.suffix in ['.bmp', '.jpg', '.png']]\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        target_img = Image.open(self.filenames[index]).convert('RGB')\n",
    "\n",
    "        input_img = target_img.resize((target_img.size[0] // self.scale_factor, target_img.size[1] // self.scale_factor), Image.BICUBIC)\n",
    "        input_img = input_img.resize(target_img.size, Image.BICUBIC)\n",
    "\n",
    "        return ToTensor()(input_img), ToTensor()(target_img), Path(self.filenames[index]).stem\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データ読み込み   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = DatasetLoader4Train(image_dir='./data/General-100/train', patch_size=96, scale_factor=4, data_augmentation=not opt.naive)\n",
    "train_loader = DataLoader(dataset=train_set, batch_size=10, shuffle=True)\n",
    "\n",
    "val_set = DatasetLoader4Eval(image_dir='./data/General-100/val', scale_factor=4)\n",
    "val_loader = DataLoader(dataset=val_set, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SRCNNモデル定義  \n",
    "論文に従いモデルを定義   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=9, padding=4)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=1, padding=0)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=3, kernel_size=5, padding=2)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d)):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.001)\n",
    "                nn.init.constant_(m.bias, val=0)\n",
    "\n",
    "            self.params = [\n",
    "                        {'params': self.conv1.parameters()},\n",
    "                        {'params': self.conv2.parameters()},\n",
    "                        {'params': self.conv3.parameters(),\n",
    "                        'lr': 1e-5}]\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = relu(x)\n",
    "        x = self.conv3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SRCNNモデル改  \n",
    "原論文では、カーネルサイズ９x９の特徴抽出層が第１層に当たる  \n",
    "これにカーネルサイズ１１x１１の層を追加し広範囲の特徴抽出を行う  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNN11(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRCNN11, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=9, padding=4)\n",
    "        self.conv11= nn.Conv2d(in_channels=3, out_channels=32, kernel_size=11, padding=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=32, kernel_size=1, padding=0)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=3, kernel_size=5, padding=2)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d)):\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.001)\n",
    "                nn.init.constant_(m.bias, val=0)\n",
    "\n",
    "        self.params = [\n",
    "                        {'params': self.conv1.parameters()},\n",
    "                        {'params': self.conv11.parameters()},\n",
    "                        {'params': self.conv2.parameters()},\n",
    "                        {'params': self.conv3.parameters(),\n",
    "                        'lr': 1e-5}]\n",
    "    def forward(self, x):\n",
    "        x9 = self.conv1(x)\n",
    "        x9 = relu(x9)\n",
    "        x11 = self.conv11(x)\n",
    "        x11 = relu(x11)\n",
    "        x = torch.cat((x9, x11),dim=1)\n",
    "        x = self.conv2(x)\n",
    "        x = relu(x)\n",
    "        x = self.conv3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用モデルのインスタンス  \n",
    "モデルインスタンス  \n",
    "オプティマイザ定義  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    if opt.c11:\n",
    "        model = SRCNN11()\n",
    "    else:\n",
    "        model = SRCNN()\n",
    "except:\n",
    "    model = SRCNN()\n",
    "\n",
    "criterion = MSELoss()\n",
    "if opt.cuda:\n",
    "    model = model.cuda()\n",
    "    criterion = criterion.cuda()\n",
    "\n",
    "optimizer = optim.Adam( model.params, lr=1e-4 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop with MiniBatch  \n",
    "epoch and snapshot size can be specified command args  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    epochs = opt.epoch\n",
    "    snaps  = opt.snap\n",
    "except:\n",
    "    epochs = 5*10000\n",
    "    snaps  = 5*  100\n",
    "progressPSNR = []\n",
    "progressLoss = []\n",
    "from pdb import set_trace\n",
    "for epoch in range(epochs):\n",
    "    model.train() # Training Phase\n",
    "    epoch_loss, epoch_psnr = 0, 0\n",
    "    for batch in train_loader:\n",
    "        inputs, targets = Variable(batch[0]), Variable(batch[1])\n",
    "        if opt.cuda:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(inputs)\n",
    "        loss = criterion(prediction, targets)\n",
    "        epoch_loss += loss.data\n",
    "        epoch_psnr += 10 * log10(1 / loss.data)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('[Epoch {}] Loss: {:.4f}, PSNR: {:.4f} dB'.format(epoch + 1, epoch_loss / len(train_loader), epoch_psnr / len(train_loader)))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    if (epoch + 1) % snaps != 0:\n",
    "        continue\n",
    "\n",
    "    model.eval()  # Validation Phase\n",
    "    val_loss, val_psnr = 0, 0\n",
    "    val_loss0,val_psnr0= 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            inputs, targets = batch[0], batch[1]\n",
    "            if opt.cuda:\n",
    "                inputs = inputs.cuda()\n",
    "                targets = targets.cuda()\n",
    "\n",
    "            prediction = model(inputs)\n",
    "            loss = criterion(prediction, targets)\n",
    "            val_loss += loss.data\n",
    "            val_psnr += 10 * log10(1 / loss.data)\n",
    "            \n",
    "            loss0= criterion(inputs, targets)\n",
    "            val_loss0+= loss0.data\n",
    "            val_psnr0+= 10 * log10(1 / loss0.data)\n",
    "\n",
    "            pred_file   = sample_dir / '{}_epoch{:05}.png'.format(batch[2][0], epoch + 1)\n",
    "            target_file = sample_dir / '{}_epoch{:05}.png'.format(batch[2][0], 00000)\n",
    "            save_image(prediction, pred_file, nrow=1)\n",
    "            if not target_file.exists(): save_image(targets, target_file, nrow=1)\n",
    "\n",
    "    avrg_loss0= val_loss0/ len(val_loader) # For Validation\n",
    "    avrg_psnr0= val_psnr0/ len(val_loader)\n",
    "    avrg_loss = val_loss / len(val_loader) # For Prediction\n",
    "    avrg_psnr = val_psnr / len(val_loader)\n",
    "    progressPSNR.append(avrg_psnr)\n",
    "    progressLoss.append(avrg_loss)\n",
    "    print(\"===> Avrg Loss: {:.4f} PSNR: {:.4f} dB [ VAL {:.4f} / {:.4f} dB ]\".format(avrg_loss, avrg_psnr, avrg_loss0, avrg_psnr0))\n",
    "    np.save(str(resultdB),progressPSNR)\n",
    "    \n",
    "    torch.save(model.state_dict(), str(result_dir / 'latest_weight.pth')) # Save Latest Weight\n",
    "    torch.save(model.state_dict(), str(weight_dir / 'weight_epoch{:05}.pth'.format(epoch + 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "後処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve stdio\n",
    "if result_fileout:\n",
    "    sys.stdout = backup_stdout if backup_stdout else None\n",
    "    sys.stderr = backup_stderr if backup_stderr else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
